!pip install tashaphyne
import gensim
from gensim.models import KeyedVectors
from gensim.models import word2vec

!unzip '/kaggle/working/AraVec'
!rm AraVec
import nltk
import pandas as pd
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
from tashaphyne.stemming import ArabicLightStemmer
import re
import emoji
from nltk.corpus import stopwords
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import LSTM, Dense, Embedding
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import TensorDataset
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f'There are {torch.cuda.device_count()} GPU(s) available.')
    print('Device name:', torch.cuda.get_device_name(0))

else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")
from sklearn.preprocessing import LabelEncoder
nltk.download('stopwords')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Data preprocessing ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

test=pd.read_csv("/kaggle/input/neural/test_no_label.csv")
df=pd.read_csv("/kaggle/input/neural/train1.csv")
#print(df)
df = df.iloc[:]
# print("print data", df)
# print(len(df))
# Remove duplicated
df.review_description.duplicated().sum()
df.drop(df[df.review_description.duplicated() == True].index, axis=0, inplace=True)


# Remove Punctuation
df.review_description = df.review_description.astype(str)
df.review_description = df.review_description.apply(
    lambda x: re.sub('[%s]' % re.escape("""!"#$%&'()*+,ØŒ-./:;<=>ØŸ?@[\]^_`{|}~"""), ' ', x))
df.review_description = df.review_description.apply(lambda x: x.replace('Ø›', "", ))
# print("print data after pun", df.head())


# Define the function to remove consecutive duplicated Arabic words
def remove_duplicate_arabic_words(text):
    # Tokenize the text into words
    words = text.split()

    # Remove consecutive duplicated words
    unique_words = [words[i] for i in range(len(words)) if i == 0 or words[i] != words[i - 1]]

    # Join the unique words back into a sentence
    modified_text = ' '.join(unique_words)

    return modified_text


df['review_description'] = df['review_description'].apply(remove_duplicate_arabic_words)
# Remove StopWords
stopWords = list(set(stopwords.words("arabic")))  ## To remove duplictes and return to list again

# Some words needed to work with to will remove
for word in ['Ù„Ø§', 'Ù„ÙƒÙ†', 'ÙˆÙ„ÙƒÙ†']:
    stopWords.remove(word)
df.review_description = df.review_description.apply(
    lambda x: " ".join([word for word in x.split() if word not in stopWords]))
# print("print data after removing stop words", df.head())

# Replace Emoji by Text
emojis = {"ğŸ™‚": "ÙŠØ¨ØªØ³Ù…", "ğŸ˜‚": "ÙŠØ¶Ø­Ùƒ", "ğŸ’”": "Ù‚Ù„Ø¨ Ø­Ø²ÙŠÙ†", "ğŸ™‚": "ÙŠØ¨ØªØ³Ù…", "â¤": "Ø­Ø¨", "â¤": "Ø­Ø¨", "ğŸ˜": "Ø­Ø¨", "ğŸ˜­": "ÙŠØ¨ÙƒÙŠ",
          "ğŸ˜¢": "Ø­Ø²Ù†", "ğŸ˜”": "Ø­Ø²Ù†", "â™¥": "Ø­Ø¨", "ğŸ’œ": "Ø­Ø¨", "ğŸ˜…": "ÙŠØ¶Ø­Ùƒ", "ğŸ™": "Ø­Ø²ÙŠÙ†", "ğŸ’•": "Ø­Ø¨", "ğŸ’™": "Ø­Ø¨", "ğŸ˜": "Ø­Ø²ÙŠÙ†",
          "ğŸ˜Š": "Ø³Ø¹Ø§Ø¯Ø©", "ğŸ‘": "ÙŠØµÙÙ‚", "ğŸ‘Œ": "Ø§Ø­Ø³Ù†Øª", "ğŸ˜´": "ÙŠÙ†Ø§Ù…", "ğŸ˜€": "ÙŠØ¶Ø­Ùƒ", "ğŸ˜Œ": "Ø­Ø²ÙŠÙ†", "ğŸŒ¹": "ÙˆØ±Ø¯Ø©", "ğŸ™ˆ": "Ø­Ø¨",
          "ğŸ˜„": "ÙŠØ¶Ø­Ùƒ", "ğŸ˜": "Ù…Ø­Ø§ÙŠØ¯", "âœŒ": "Ù…Ù†ØªØµØ±", "âœ¨": "Ù†Ø¬Ù…Ù‡", "ğŸ¤”": "ØªÙÙƒÙŠØ±", "ğŸ˜": "ÙŠØ³ØªÙ‡Ø²Ø¡", "ğŸ˜’": "ÙŠØ³ØªÙ‡Ø²Ø¡", "ğŸ™„": "Ù…Ù„Ù„",
          "ğŸ˜•": "Ø¹ØµØ¨ÙŠØ©", "ğŸ˜ƒ": "ÙŠØ¶Ø­Ùƒ", "ğŸŒ¸": "ÙˆØ±Ø¯Ø©", "ğŸ˜“": "Ø­Ø²Ù†", "ğŸ’": "Ø­Ø¨", "ğŸ’—": "Ø­Ø¨", "ğŸ˜‘": "Ù…Ù†Ø²Ø¹Ø¬", "ğŸ’­": "ØªÙÙƒÙŠØ±",
          "ğŸ˜": "Ø«Ù‚Ø©", "ğŸ’›": "Ø­Ø¨", "ğŸ˜©": "Ø­Ø²ÙŠÙ†", "ğŸ’ª": "Ø¹Ø¶Ù„Ø§Øª", "ğŸ‘": "Ù…ÙˆØ§ÙÙ‚", "ğŸ™ğŸ»": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨", "ğŸ˜³": "Ù…ØµØ¯ÙˆÙ…", "ğŸ‘ğŸ¼": "ØªØµÙÙŠÙ‚",
          "ğŸ¶": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ", "ğŸŒš": "ØµÙ…Øª", "ğŸ’š": "Ø­Ø¨", "ğŸ™": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨", "ğŸ’˜": "Ø­Ø¨", "ğŸƒ": "Ø³Ù„Ø§Ù…", "â˜º": "ÙŠØ¶Ø­Ùƒ", "ğŸ¸": "Ø¶ÙØ¯Ø¹",
          "ğŸ˜¶": "Ù…ØµØ¯ÙˆÙ…", "âœŒ": "Ù…Ø±Ø­", "âœ‹ğŸ»": "ØªÙˆÙ‚Ù", "ğŸ˜‰": "ØºÙ…Ø²Ø©", "ğŸŒ·": "Ø­Ø¨", "ğŸ™ƒ": "Ù…Ø¨ØªØ³Ù…", "ğŸ˜«": "Ø­Ø²ÙŠÙ†", "ğŸ˜¨": "Ù…ØµØ¯ÙˆÙ…",
          "ğŸ¼ ": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ", "ğŸ": "Ù…Ø±Ø­", "ğŸ‚": "Ù…Ø±Ø­", "ğŸ’Ÿ": "Ø­Ø¨", "ğŸ˜ª": "Ø­Ø²Ù†", "ğŸ˜†": "ÙŠØ¶Ø­Ùƒ", "ğŸ˜£": "Ø§Ø³ØªÙŠØ§Ø¡", "â˜º": "Ø­Ø¨",
          "ğŸ˜±": "ÙƒØ§Ø±Ø«Ø©", "ğŸ˜": "ÙŠØ¶Ø­Ùƒ", "ğŸ˜–": "Ø§Ø³ØªÙŠØ§Ø¡", "ğŸƒğŸ¼": "ÙŠØ¬Ø±ÙŠ", "ğŸ˜¡": "ØºØ¶Ø¨", "ğŸš¶": "ÙŠØ³ÙŠØ±", "ğŸ¤•": "Ù…Ø±Ø¶", "â€¼": "ØªØ¹Ø¬Ø¨",
          "ğŸ•Š": "Ø·Ø§Ø¦Ø±", "ğŸ‘ŒğŸ»": "Ø§Ø­Ø³Ù†Øª", "â£": "Ø­Ø¨", "ğŸ™Š": "Ù…ØµØ¯ÙˆÙ…", "ğŸ’ƒ": "Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­", "ğŸ’ƒğŸ¼": "Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­", "ğŸ˜œ": "Ù…Ø±Ø­",
          "ğŸ‘Š": "Ø¶Ø±Ø¨Ø©", "ğŸ˜Ÿ": "Ø§Ø³ØªÙŠØ§Ø¡", "ğŸ’–": "Ø­Ø¨", "ğŸ˜¥": "Ø­Ø²Ù†", "ğŸ»": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ", "âœ’": "ÙŠÙƒØªØ¨", "ğŸš¶ğŸ»": "ÙŠØ³ÙŠØ±", "ğŸ’": "Ø§Ù„Ù…Ø§Ø¸",
          "ğŸ˜·": "ÙˆØ¨Ø§Ø¡ Ù…Ø±Ø¶", "â˜": "ÙˆØ§Ø­Ø¯", "ğŸš¬": "ØªØ¯Ø®ÙŠÙ†", "ğŸ’": "ÙˆØ±Ø¯", "ğŸŒ": "Ø´Ù…Ø³", "ğŸ‘†": "Ø§Ù„Ø§ÙˆÙ„", "âš ": "ØªØ­Ø°ÙŠØ±",
          "ğŸ¤—": "Ø§Ø­ØªÙˆØ§Ø¡", "âœ–": "ØºÙ„Ø·", "ğŸ“": "Ù…ÙƒØ§Ù†", "ğŸ‘¸": "Ù…Ù„ÙƒÙ‡", "ğŸ‘‘": "ØªØ§Ø¬", "âœ”": "ØµØ­", "ğŸ’Œ": "Ù‚Ù„Ø¨", "ğŸ˜²": "Ù…Ù†Ø¯Ù‡Ø´",
          "ğŸ’¦": "Ù…Ø§Ø¡", "ğŸš«": "Ø®Ø·Ø§", "ğŸ‘ğŸ»": "Ø¨Ø±Ø§ÙÙˆ", "ğŸŠ": "ÙŠØ³Ø¨Ø­", "ğŸ‘ğŸ»": "ØªÙ…Ø§Ù…", "â­•": "Ø¯Ø§Ø¦Ø±Ù‡ ÙƒØ¨ÙŠØ±Ù‡", "ğŸ·": "Ø³Ø§ÙƒØ³ÙÙˆÙ†",
          "ğŸ‘‹": "ØªÙ„ÙˆÙŠØ­ Ø¨Ø§Ù„ÙŠØ¯", "âœŒğŸ¼": "Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±", "ğŸŒ": "Ù…Ø¨ØªØ³Ù…", "â¿": "Ø¹Ù‚Ø¯Ù‡ Ù…Ø²Ø¯ÙˆØ¬Ù‡", "ğŸ’ªğŸ¼": "Ù‚ÙˆÙŠ", "ğŸ“©": "ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙŠ",
          "â˜•": "Ù‚Ù‡ÙˆÙ‡", "ğŸ˜§": "Ù‚Ù„Ù‚ Ùˆ ØµØ¯Ù…Ø©", "ğŸ—¨": "Ø±Ø³Ø§Ù„Ø©", "â—": "ØªØ¹Ø¬Ø¨", "ğŸ™†ğŸ»": "Ø§Ø´Ø§Ø±Ù‡ Ù…ÙˆØ§ÙÙ‚Ù‡", "ğŸ‘¯": "Ø§Ø®ÙˆØ§Øª", "Â©": "Ø±Ù…Ø²",
          "ğŸ‘µğŸ½": "Ø³ÙŠØ¯Ù‡ Ø¹Ø¬ÙˆØ²Ù‡", "ğŸ£": "ÙƒØªÙƒÙˆØª", "ğŸ™Œ": "ØªØ´Ø¬ÙŠØ¹", "ğŸ™‡": "Ø´Ø®Øµ ÙŠÙ†Ø­Ù†ÙŠ", "ğŸ‘ğŸ½": "Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡", "ğŸ‘ŒğŸ½": "Ø¨Ø§Ù„Ø¸Ø¨Ø·",
          "â‰": "Ø§Ø³ØªÙ†ÙƒØ§Ø±", "âš½": "ÙƒÙˆØ±Ù‡", "ğŸ•¶": "Ø­Ø¨", "ğŸˆ": "Ø¨Ø§Ù„ÙˆÙ†", "ğŸ€": "ÙˆØ±Ø¯Ù‡", "ğŸ’µ": "ÙÙ„ÙˆØ³", "ğŸ˜‹": "Ø¬Ø§Ø¦Ø¹", "ğŸ˜›": "ÙŠØºÙŠØ¸",
          "ğŸ˜ ": "ØºØ§Ø¶Ø¨", "âœğŸ»": "ÙŠÙƒØªØ¨", "ğŸŒ¾": "Ø§Ø±Ø²", "ğŸ‘£": "Ø§Ø«Ø± Ù‚Ø¯Ù…ÙŠÙ†", "âŒ": "Ø±ÙØ¶", "ğŸŸ": "Ø·Ø¹Ø§Ù…", "ğŸ‘¬": "ØµØ¯Ø§Ù‚Ø©", "ğŸ°": "Ø§Ø±Ù†Ø¨",
          "â˜‚": "Ù…Ø·Ø±", "âšœ": "Ù…Ù…Ù„ÙƒØ© ÙØ±Ù†Ø³Ø§", "ğŸ‘": "Ø®Ø±ÙˆÙ", "ğŸ—£": "ØµÙˆØª Ù…Ø±ØªÙØ¹", "ğŸ‘ŒğŸ¼": "Ø§Ø­Ø³Ù†Øª", "â˜˜": "Ù…Ø±Ø­", "ğŸ˜®": "ØµØ¯Ù…Ø©",
          "ğŸ˜¦": "Ù‚Ù„Ù‚", "â­•": "Ø§Ù„Ø­Ù‚", "âœ": "Ù‚Ù„Ù…", "â„¹": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "ğŸ™ğŸ»": "Ø±ÙØ¶", "âšª": "Ù†Ø¶Ø§Ø±Ø© Ù†Ù‚Ø§Ø¡", "ğŸ¤": "Ø­Ø²Ù†", "ğŸ’«": "Ù…Ø±Ø­",
          "ğŸ’": "Ø­Ø¨", "ğŸ”": "Ø·Ø¹Ø§Ù…", "â¤": "Ø­Ø¨", "âœˆ": "Ø³ÙØ±", "ğŸƒğŸ»â€â™€": "ÙŠØ³ÙŠØ±", "ğŸ³": "Ø°ÙƒØ±", "ğŸ¤": "Ù…Ø§ÙŠÙƒ ØºÙ†Ø§Ø¡", "ğŸ¾": "ÙƒØ±Ù‡",
          "ğŸ”": "Ø¯Ø¬Ø§Ø¬Ø©", "ğŸ™‹": "Ø³Ø¤Ø§Ù„", "ğŸ“®": "Ø¨Ø­Ø±", "ğŸ’‰": "Ø¯ÙˆØ§Ø¡", "ğŸ™ğŸ¼": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨", "ğŸ’‚ğŸ¿ ": "Ø­Ø§Ø±Ø³", "ğŸ¬": "Ø³ÙŠÙ†Ù…Ø§",
          "â™¦": "Ù…Ø±Ø­", "ğŸ’¡": "Ù‚ÙƒØ±Ø©", "â€¼": "ØªØ¹Ø¬Ø¨", "ğŸ‘¼": "Ø·ÙÙ„", "ğŸ”‘": "Ù…ÙØªØ§Ø­", "â™¥": "Ø­Ø¨", "ğŸ•‹": "ÙƒØ¹Ø¨Ø©", "ğŸ“": "Ø¯Ø¬Ø§Ø¬Ø©",
          "ğŸ’©": "Ù…Ø¹ØªØ±Ø¶", "ğŸ‘½": "ÙØ¶Ø§Ø¦ÙŠ", "â˜”": "Ù…Ø·Ø±", "ğŸ·": "Ø¹ØµÙŠØ±", "ğŸŒŸ": "Ù†Ø¬Ù…Ø©", "â˜": "Ø³Ø­Ø¨", "ğŸ‘ƒ": "Ù…Ø¹ØªØ±Ø¶", "ğŸŒº": "Ù…Ø±Ø­",
          "ğŸ”ª": "Ø³ÙƒÙŠÙ†Ø©", "â™¨": "Ø³Ø®ÙˆÙ†ÙŠØ©", "ğŸ‘ŠğŸ¼": "Ø¶Ø±Ø¨", "âœ": "Ù‚Ù„Ù…", "ğŸš¶ğŸ¾â€â™€": "ÙŠØ³ÙŠØ±", "ğŸ‘Š": "Ø¶Ø±Ø¨Ø©", "â—¾": "ÙˆÙ‚Ù", "ğŸ˜š": "Ø­Ø¨",
          "ğŸ”¸": "Ù…Ø±Ø­", "ğŸ‘ğŸ»": "Ù„Ø§ ÙŠØ¹Ø¬Ø¨Ù†ÙŠ", "ğŸ‘ŠğŸ½": "Ø¶Ø±Ø¨Ø©", "ğŸ˜™": "Ø­Ø¨", "ğŸ¥": "ØªØµÙˆÙŠØ±", "ğŸ‘‰": "Ø¬Ø°Ø¨ Ø§Ù†ØªØ¨Ø§Ù‡", "ğŸ‘ğŸ½": "ÙŠØµÙÙ‚",
          "ğŸ’ªğŸ»": "Ø¹Ø¶Ù„Ø§Øª", "ğŸ´": "Ø§Ø³ÙˆØ¯", "ğŸ”¥": "Ø­Ø±ÙŠÙ‚", "ğŸ˜¬": "Ø¹Ø¯Ù… Ø§Ù„Ø±Ø§Ø­Ø©", "ğŸ‘ŠğŸ¿": "ÙŠØ¶Ø±Ø¨", "ğŸŒ¿": "ÙˆØ±Ù‚Ù‡ Ø´Ø¬Ø±Ù‡", "âœ‹ğŸ¼": "ÙƒÙ Ø§ÙŠØ¯",
          "ğŸ‘": "Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡", "â˜ ": "ÙˆØ¬Ù‡ Ù…Ø±Ø¹Ø¨", "ğŸ‰": "ÙŠÙ‡Ù†Ø¦", "ğŸ”•": "ØµØ§Ù…Øª", "ğŸ˜¿": "ÙˆØ¬Ù‡ Ø­Ø²ÙŠÙ†", "â˜¹": "ÙˆØ¬Ù‡ ÙŠØ§Ø¦Ø³", "ğŸ˜˜": "Ø­Ø¨",
          "ğŸ˜°": "Ø®ÙˆÙ Ùˆ Ø­Ø²Ù†", "ğŸŒ¼": "ÙˆØ±Ø¯Ù‡", "ğŸ’‹": "Ø¨ÙˆØ³Ù‡", "ğŸ‘‡": "Ù„Ø§Ø³ÙÙ„", "â£": "Ø­Ø¨", "ğŸ§": "Ø³Ù…Ø§Ø¹Ø§Øª", "ğŸ“": "ÙŠÙƒØªØ¨", "ğŸ˜‡": "Ø¯Ø§ÙŠØ®",
          "ğŸ˜ˆ": "Ø±Ø¹Ø¨", "ğŸƒ": "ÙŠØ¬Ø±ÙŠ", "âœŒğŸ»": "Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±", "ğŸ”«": "ÙŠØ¶Ø±Ø¨", "â—": "ØªØ¹Ø¬Ø¨", "ğŸ‘": "ØºÙŠØ± Ù…ÙˆØ§ÙÙ‚", "ğŸ”": "Ù‚ÙÙ„",
          "ğŸ‘ˆ": "Ù„Ù„ÙŠÙ…ÙŠÙ†", "â„¢": "Ø±Ù…Ø²", "ğŸš¶ğŸ½": "ÙŠØªÙ…Ø´ÙŠ", "ğŸ˜¯": "Ù…ØªÙØ§Ø¬Ø£", "âœŠ": "ÙŠØ¯ Ù…ØºÙ„Ù‚Ù‡", "ğŸ˜»": "Ø§Ø¹Ø¬Ø§Ø¨", "ğŸ™‰": "Ù‚Ø±Ø¯",
          "ğŸ‘§": "Ø·ÙÙ„Ù‡ ØµØºÙŠØ±Ù‡", "ğŸ”´": "Ø¯Ø§Ø¦Ø±Ù‡ Ø­Ù…Ø±Ø§Ø¡", "ğŸ’ªğŸ½": "Ù‚ÙˆÙ‡", "ğŸ’¤": "ÙŠÙ†Ø§Ù…", "ğŸ‘€": "ÙŠÙ†Ø¸Ø±", "âœğŸ»": "ÙŠÙƒØªØ¨", "â„": "ØªÙ„Ø¬",
          "ğŸ’€": "Ø±Ø¹Ø¨", "ğŸ˜¤": "ÙˆØ¬Ù‡ Ø¹Ø§Ø¨Ø³", "ğŸ–‹": "Ù‚Ù„Ù…", "ğŸ©": "ÙƒØ§Ø¨", "â˜•": "Ù‚Ù‡ÙˆÙ‡", "ğŸ˜¹": "Ø¶Ø­Ùƒ", "ğŸ’“": "Ø­Ø¨", "â˜„ ": "Ù†Ø§Ø±",
          "ğŸ‘»": "Ø±Ø¹Ø¨", "â": "Ø®Ø·Ø¡", "ğŸ¤®": "Ø­Ø²Ù†", 'ğŸ»': "Ø§Ø­Ù…Ø±"}
emoticons_to_emoji = {":)": "ğŸ™‚", ":(": "ğŸ™", "xD": "ğŸ˜†", ":=(": "ğŸ˜­", ":'(": "ğŸ˜¢", ":'â€‘(": "ğŸ˜¢", "XD": "ğŸ˜‚", ":D": "ğŸ™‚",
                      "â™¬": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ", "â™¡": "â¤", "â˜»": "ğŸ™‚"}


def checkemojie(text):
    emojistext = []
    for char in text:
        if any(emoji.distinct_emoji_list(char)) and char in emojis.keys():
            emojistext.append(emojis[emoji.distinct_emoji_list(char)[0]])
    return " ".join(emojistext)


def emojiTextTransform(text):
    cleantext = re.sub(r'[^\w\s]', '', text)
    return cleantext + " " + checkemojie(text)


# Apply checkemojie and emojiTextTransform
df['review_description'] = df['review_description'].apply(lambda x: emojiTextTransform(x))
# print("print data after changing the emoji to text", df['review_description'].head())

# Remove Numbers
df.review_description = df.review_description.apply(lambda x: ''.join([word for word in x if not word.isdigit()]))

# Apply Stemming
arabic_stemmer = ArabicLightStemmer()
# Apply stemming to the 'review_description' column
df['review_description'] = df['review_description'].apply(
    lambda x: " ".join([arabic_stemmer.light_stem(word) for word in x.split()]))


hidden_dim =264 
output_size = 3 
num_layers = 2  
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initializations and corrections to your code
df.dropna(subset=['review_description'], inplace=True)
review_description = df['review_description']
y = df['rating']  # 1, 0, -1

tokenizer = Tokenizer()
tokenizer.fit_on_texts(review_description)
seq = tokenizer.texts_to_sequences(review_description)
seq_pad = pad_sequences(seq, maxlen=150, padding="post", truncating="post")
vocab_size = len(tokenizer.word_index) + 1

w2v_embeddings_index = {}
TOTAL_EMBEDDING_DIM = 300
embeddings_file = '/kaggle/working/full_grams_cbow_300_twitter.mdl'
w2v_model = KeyedVectors.load(embeddings_file)

for word in w2v_model.wv.index_to_key:
    w2v_embeddings_index[word] = w2v_model.wv[word]

embedding_matrix = np.zeros((vocab_size, TOTAL_EMBEDDING_DIM))
for word, i in tokenizer.word_index.items():
    embedding_vector = w2v_embeddings_index.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ LSTM model ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

class LSTMModel(nn.Module):
    def _init_(self, vocab_size, embed_dim, hidden_dim, output_size, num_layers, embedding_matrix):
        super(LSTMModel, self)._init_()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float))
        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, dropout=0.5, batch_first=True, bidirectional=True)
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(hidden_dim * 2, output_size)  

    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out, (h_n, c_n) = self.lstm(embedded)
        lstm_out = self.dropout(lstm_out)
        out = lstm_out[:, -1] 
        out = self.fc(out)  

        return out 
model = LSTMModel(vocab_size, TOTAL_EMBEDDING_DIM, hidden_dim, output_size, num_layers, embedding_matrix).to(device)

from torch.optim.lr_scheduler import ReduceLROnPlateau


optimizer = optim.Adam(model.parameters(),0.1)
lossfun = nn.CrossEntropyLoss()
scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)

def ApplyLstm(model, train_loader, val_loader, optimizer, lossfun, scheduler, epochs):
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        correct_predictions = 0
        total_predictions = 0

        for text, labels in train_loader:
            text, labels = text.to(device), labels.to(device)
            optimizer.zero_grad()
            output = model(text)
            loss = lossfun(output, labels)
            total_loss += loss.item()
            predicted_classes = torch.argmax(output, dim=1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted_classes == labels).sum().item()
            loss.backward()
            optimizer.step()

        val_loss = 0
        model.eval()
        with torch.no_grad():
            for text, labels in val_loader:
                text, labels = text.to(device), labels.to(device)
                output = model(text)
                loss = lossfun(output, labels)
                val_loss += loss.item()

        avg_train_loss = total_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        accuracy = correct_predictions / total_predictions * 100

        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')

        scheduler.step(avg_val_loss)

from sklearn.preprocessing import LabelEncoder


le = LabelEncoder()

y_encoded = le.fit_transform(y)  # This will transform -1, 0, 1 to 0, 1, 2

X = torch.from_numpy(seq_pad).long().to(device)
y_encoded = torch.tensor(y_encoded).long().to(device)
dataset = TensorDataset(X, y_encoded)

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)

ApplyLstm(model, train_loader, val_loader, optimizer, lossfun, scheduler, epochs=50)
test=pd.read_csv("/kaggle/input/neural/test _no_label.csv")
test['review_description'] = test['review_description'].apply(remove_duplicate_arabic_words)
test['review_description'] = test['review_description'].apply(
    lambda x: " ".join([word for word in x.split() if word not in stopWords]))
test['review_description'] = test['review_description'].apply(lambda x: emojiTextTransform(x))
test['review_description'] = test['review_description'].apply(lambda x: ''.join([word for word in x if not word.isdigit()]))
test['review_description'] = test['review_description'].apply(
    lambda x: " ".join([arabic_stemmer.light_stem(word) for word in x.split()]))

test_seq = tokenizer.texts_to_sequences(test['review_description'])
test_seq_pad = pad_sequences(test_seq, maxlen=150, padding="post", truncating="post")
X_test = torch.from_numpy(test_seq_pad).long().to(device)

model.eval()
with torch.no_grad():
    output = model(X_test)
    predicted_classes = torch.argmax(output, dim=1)

predicted_labels = le.inverse_transform(predicted_classes.cpu().numpy())
test['predicted_label'] = predicted_labels


test.to_csv('predicted_labels4.csv', columns=['ID', 'review_description', 'predicted_label'], index=False, encoding='utf-8-sig')